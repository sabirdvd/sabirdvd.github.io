<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>How Effectively Do LLMs Extract Feature-Sentiment Pairs from App Reviews?</title>
    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
    <link href="style.css" rel="stylesheet" type="text/css" />

     <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    .responsive-img {
      max-width: 90%;   /* Ensures the image never exceeds the width of its container */
      height: auto;      /* Maintains the aspect ratio */
      display: block;    /* Makes the image a block element */
      margin-left: auto; /* Centers the image horizontally */
      margin-right: auto;/* Centers the image horizontally */
    }
  </style>
    
<script type="text/javascript" src="../js/hidebib.js"></script>


   

</head> 

<body> 

        <style>

  body {
    font-size: 19px; 
  }
</style>


<!--
<div class="container">
    <table border="0" align="center">
        <tr><td width="623" align="center" valign="middle"><h2>A Fine-grained Sentiment Analysis of App Reviews
                using Large Language Models: An Evaluation Study</h2></td></tr>
--> 
        
<div class="container">
    <table border="0" align="center">
        <tr><td width="623" align="center" valign="middle"><h2>How Effectively Do LLMs Extract Feature-Sentiment Pairs from App Reviews?</h2></td></tr>


        
<!-- <tr><td width="300" align="center" valign="middle">   <a href="">Anonymous<sup></sup></a></tr> -->

 
      <tr><td width="300" align="center" valign="middle" style="font-size: 20px;">   <a href="https://www.linkedin.com/in/faiz-ali-shah-018547a/">Faiz Ali Shah</a>, <a href="https://kodu.ut.ee/~ahmedabdulmajeed/">Ahmed Sabir</a>, 
        <a href="https://rajeshsharma.cs.ut.ee">Rajesh Sharma <sup></sup></a> <a href="https://sep.cs.ut.ee/Main/People"> and Dietmar Pfahl <sup><sup></sup></a> </td></tr>

         
        

    <tr><td width="300" align="center" valign="middle"> University of Tartu, Institute of Computer Science, Tartu, Estonia</a><sup></sup></td></tr> 
  </table>
  </br>


     <p align="center"> 
    <img src="LLM-app.png" class="responsive-img" alt="Description of image" />
  </p>
    
<!--   <p>
  <p align="center"> <img src="LLM-app.png" width="900" align="middle" /></p>

</p>
 -->



</table>
<table width="400px" align="center">
  <tr>
    <td align=center width=100px>
      <center>
        <ul class="nav">
          <li class="nav-item text-center">
              <a href="https://arxiv.org/abs/2409.07162" class="nav-link" title="Temp link">
                  <svg style="width:40px;height:40px" viewBox="0 0 24 24">
                      <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z" />
                  </svg><br>
                  Paper
              </a>
      </center>
    </td>
    <td align=center width=200px>
      <center>
        
        <ul class="nav">
        <li class="nav-item text-center">
          <a href="https://github.com/Faiz-UT/Eval-Feature-Sentiment-Extraction-LLMs" class="nav-link">
              <svg style="width:40px;height:40px" viewBox="0 0 65 65">
                  <path fill="currentColor" d="M32 0a32.021 32.021 0 0 0-10.1 62.4c1.6.3 2.2-.7 2.2-1.5v-6c-8.9 1.9-10.8-3.8-10.8-3.8-1.5-3.7-3.6-4.7-3.6-4.7-2.9-2 .2-1.9.2-1.9 3.2.2 4.9 3.3 4.9 3.3 2.9 4.9 7.5 3.5 9.3 2.7a6.93 6.93 0 0 1 2-4.3c-7.1-.8-14.6-3.6-14.6-15.8a12.27 12.27 0 0 1 3.3-8.6 11.965 11.965 0 0 1 .3-8.5s2.7-.9 8.8 3.3a30.873 30.873 0 0 1 8-1.1 30.292 30.292 0 0 1 8 1.1c6.1-4.1 8.8-3.3 8.8-3.3a11.965 11.965 0 0 1 .3 8.5 12.1 12.1 0 0 1 3.3 8.6c0 12.3-7.5 15-14.6 15.8a7.746 7.746 0 0 1 2.2 5.9v8.8c0 .9.6 1.8 2.2 1.5A32.021 32.021 0 0 0 32 0z" />
              </svg> <br>
             
              Code
          </a>
      </center>
      <td align=center width=100px>
        <center>
          <ul class="nav">
          <li class="nav-item text-center">
            <a href="https://colab.research.google.com/drive/1vi9NeZgUpHY7MOu0rCefBIb9ztwPw255?usp=sharing" class="nav-link">
              <svg style="width:40px;height:40px" viewBox="0 0 24 24">
                <path fill="currentColor" d="M21,16.5C21,16.88 20.79,17.21 20.47,17.38L12.57,21.82C12.41,21.94 12.21,22 12,22C11.79,22 11.59,21.94 11.43,21.82L3.53,17.38C3.21,17.21 3,16.88 3,16.5V7.5C3,7.12 3.21,6.79 3.53,6.62L11.43,2.18C11.59,2.06 11.79,2 12,2C12.21,2 12.41,2.06 12.57,2.18L20.47,6.62C20.79,6.79 21,7.12 21,7.5V16.5M12,4.15L6.04,7.5L12,10.85L17.96,7.5L12,4.15M5,15.91L11,19.29V12.58L5,9.21V15.91M19,15.91V9.21L13,12.58V19.29L19,15.91Z" />
              </svg><br>
              Demo
            </a>
                  </ul>
        </center>
    </td>
</table>

  
</div>

</br>

<div class="container">
         <h2 style="text-align: center;">Abstract</h2>
<!--   <h2<>Abstract/h2> -->

  
  
  
  
  


    <p align="justify">Analyzing user reviews for sentiment towards app features can provide
         valuable insights into users' perceptions of app functionality and their evolving needs. Given the
        volume of user reviews received daily, an automated mechanism to generate feature-level sentiment 
          summaries of user reviews is needed. Recent advances in Large Language Models (LLMs) such as ChatGPT
           have shown impressive performance on several new tasks without updating the model's parameters i.e., using
         zero or a few labeled examples. Despite these advancements, LLMs’ capabilities to perform feature-specific
          sentiment analysis of user reviews remain unexplored. This study compares the performance of state-of-the-art
           LLMs, including GPT-4, ChatGPT, and LLama-2-chat variants, for extracting app features and associated 
           sentiments under 0-shot, 1-shot, and 5-shot scenarios. Results indicate the best-performing GPT-4 model 
           outperforms rule-based approaches by 23.6% in f1-score with zero-shot feature extraction; 5-shot further 
           improving it by 6%. GPT-4 achieves a 74% f1-score for predicting positive sentiment towards correctly 
           predicted app features, with 5-shot enhancing it by 7%. Our study suggests that LLM models are promising
            for generating feature-specific sentiment summaries of user reviews.
        


        
      <p>



    <hr>

<!--       <h2>Quantitative Results</h2> -->
         <h2 style="text-align: center;">Quantitative Results</h2>
    <p> 
 GPT-4 is the top-performing model for extracting app features, surpassing rule-based approaches by
23.6% in f1-score with the exact matching strategy. However, the fine-tuned BERT(*) model still outperforms GPT-4 by 14%
in the f1-score. In the 5-shot scenario, both GPT-4 and Llama-2-70B show further improvements of 7% and 6% in f1-score, respectively. Our evaluation study has showcased the
encouraging performance of LLMs in extracting fine-grained information from user feedback. This capability of LLMs
holds promise in assisting developers with their software maintenance and evolution activities by analyzing users’ opinions.
</p>
    
<!-- Comparison of zero-shot, 1-shot, and 5-shot performances of LLMs for extracting app features from app reviews
using exact and partial match strategies. (Second best result (in Blue) and Third best result (in yellow) ). The (*) refers to the model fine-tuned on
a large app review  dataset. -->

 <p>
<!--             <p align="center"> <img src="table-2.png" width="1100" align="middle" /></p> -->
<!--        <p align="center"> <img src="table-3_llms_app.png" width="1100" align="middle" /></p> -->
    
     <p align="center"> 
    <img src="table-3_llms_app.png" class="responsive-img" alt="Description of image" />
  </p>
<!--       <p align="center"> <img src="table-3_llms_app.png"  align="middle" /></p> -->
    
 </p>
  <p>Second best result (in Blue) and Third best result (in yellow). </p>


    <hr> 

      <p>

            <h2 style="text-align: center;">Qualitative Results</h2>
  The analysis reveals, in 5-shot f1 performance of GPT-4, ChatGPT, LLama-2-70B Chat for individual app, that LLM models exhibit varying performance across different applications. Specifically, LLM models
demonstrate improved performance in extracting features from  user reviews of applications such as "WhatsApp," "Twitter,"
and "PhotoEditor".

<br><br>
<!--      <p align="center"> <img src=" app_result.png" width="400" align="middle" /></p>
     <p align="center"> <img src="Fig2.png" width="400" align="middle" /></p>
 -->
<div style="display: flex; justify-content: center; align-items: center;">
     <img src="Fig2.png" width="500">
  <img src="app_result.png" width="400" style="margin-right: 10px;">
 
</div>

  <p>
     Notably, (<strong>Left</strong>) All models, except LLama-7B, demonstrate improved performance with the Long-prompt for predicting neutral sentiment. (<strong>Right</strong>) all models display a low f1-score for the "Netflix" application. This observed trend may be associated with the proportion of review data from each
application employed in training or fine-tuning these models.
     </p>

    
      <p>

    <hr>
          
 The result shows feature-sentiment pairs extracted by LLama-2-70B, ChatGPT, and GPT-4 models from user reviews
Human-labeled features in reviews are highlighted and enclosed in brackets. POS, NEU, and NEG show true sentiment polarity
labels in reviews. The ✗ symbol indicates an incorrect prediction, while the ✓symbol indicates a correct prediction using the
partial match 2 evaluation strategy.
 </p>


     <p align="center"> 
    <img src="paper_example_LLMs.png" class="responsive-img" alt="Description of image" />
  </p>



  
    </table> 
</div>
   <h3 style="text-align: center;">Acknowledgment</h3>

    <div style="text-align: left; background-color: #ffffff; padding: 10px; border-radius: 5px;" class="containersmall">
        <p> This work has received funding from the EU H2020 program under the SoBigData++ project (grant agreement No. 871042), 
             CHIST-ERA grant No. CHIST-ERA-19-XAI-010, (ETAg grant No.SLTAT21096), and partially funded by HAMISON project.
        </p>
    </div>
</table> 

</table> 
</div>

</table> 
</div>

</div>

<div class="container">
</br>
<div class="box" style="text-align: left;">
  <div class="containersmall">
    <h3>Citation</h3>
    <pre class='citation' style="white-space: pre-wrap; overflow-wrap: break-word; text-align: left; direction: ltr; margin: 0;">
  @article{shah2024fine,
  title={A Fine-grained Sentiment Analysis of App Reviews using Large Language Models: An Evaluation Study},
  author={Shah, Faiz Ali and Sabir, Ahmed and Sharma, Rajesh},
  journal={arXiv preprint arXiv:2409.07162},
  year={2024}
}

    </pre>
  </div>
</div>
  <div class="containersmall" style="text-align: left;">
    <p>Contact: <a href="mailto:faiz.ali.shah@ut.ee">Faiz Ali</a></p>
  </div>
  <script xml:space="preserve" language="JavaScript">
    hideallbibs();
  </script>
</div>

</html>

