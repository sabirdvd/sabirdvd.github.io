
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Textual Visual Semantic Dataset for Text Spotting</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="style.css" rel="stylesheet" type="text/css" />

<script type="text/javascript" src="../js/hidebib.js"></script>



</head>

<body> 

<div class="container">
  <table border="0" align="center">
    <tr><td width="623" align="center" valign="middle"><h2>Textual Visual Semantic Dataset for Text Spotting </h2></td></tr>
    <tr><td width="300" align="center" valign="middle">   <a href="https://www.cs.upc.edu/~asabir/">Ahmed Sabir</a>, <a href="https://www.iri.upc.edu/people/fmoreno/">Francesc Moreno-Noguer</a>, 
         <a href="https://www.cs.upc.edu/~padro/">Lluís Padró</a></td></tr>
  </table>
  </br>
  


  <p align="center"> <img src="overview.png" width="500" align="middle" /></p>



  


</table>
<table width="400px" align="center">
  <tr>
    <td align=center width=100px>
      <center>
        <ul class="nav">
          <li class="nav-item text-center">
              <a href="https://arxiv.org/pdf/2004.10349.pdf" class="nav-link" title="Temp link">
                  <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                      <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z" />
                  </svg><br>
                  Paper
              </a>
      </center>
    </td>
    <td align=center width=200px>
      <center>
        
        <ul class="nav">
        <li class="nav-item text-center">
          <a href="https://github.com/ahmedssabir/Textual-Visual-Semantic-Dataset-for-Text-Spotting" class="nav-link">
              <svg style="width:48px;height:48px" viewBox="0 0 65 65">
                  <path fill="currentColor" d="M32 0a32.021 32.021 0 0 0-10.1 62.4c1.6.3 2.2-.7 2.2-1.5v-6c-8.9 1.9-10.8-3.8-10.8-3.8-1.5-3.7-3.6-4.7-3.6-4.7-2.9-2 .2-1.9.2-1.9 3.2.2 4.9 3.3 4.9 3.3 2.9 4.9 7.5 3.5 9.3 2.7a6.93 6.93 0 0 1 2-4.3c-7.1-.8-14.6-3.6-14.6-15.8a12.27 12.27 0 0 1 3.3-8.6 11.965 11.965 0 0 1 .3-8.5s2.7-.9 8.8 3.3a30.873 30.873 0 0 1 8-1.1 30.292 30.292 0 0 1 8 1.1c6.1-4.1 8.8-3.3 8.8-3.3a11.965 11.965 0 0 1 .3 8.5 12.1 12.1 0 0 1 3.3 8.6c0 12.3-7.5 15-14.6 15.8a7.746 7.746 0 0 1 2.2 5.9v8.8c0 .9.6 1.8 2.2 1.5A32.021 32.021 0 0 0 32 0z" />
              </svg> <br>
             
              Code
          </a>
      </center>
      <td align=center width=100px>
        <center>
          <ul class="nav">
          <li class="nav-item text-center">
            <a href="https://raw.githubusercontent.com/sabirdvd/sabirdvd.github.io/main/project_page/textual_data_2020/CVPRW_PPt_June_15__2020.pdf" class="nav-link">
              <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                <path fill="currentColor" d="M21,16.5C21,16.88 20.79,17.21 20.47,17.38L12.57,21.82C12.41,21.94 12.21,22 12,22C11.79,22 11.59,21.94 11.43,21.82L3.53,17.38C3.21,17.21 3,16.88 3,16.5V7.5C3,7.12 3.21,6.79 3.53,6.62L11.43,2.18C11.59,2.06 11.79,2 12,2C12.21,2 12.41,2.06 12.57,2.18L20.47,6.62C20.79,6.79 21,7.12 21,7.5V16.5M12,4.15L6.04,7.5L12,10.85L17.96,7.5L12,4.15M5,15.91L11,19.29V12.58L5,9.21V15.91M19,15.91V9.21L13,12.58V19.29L19,15.91Z" />
              </svg><br>
              Slide
            </a>
                  </ul>
        </center>
    </td>
</table>

  
</div>

</br>

<div class="container">
  <h2>Abstract</h2>

  
  
  
  



    <p align="justify"> Text Spotting in the wild consists of detecting and rec-ognizing text appearing in images (e.g.,  signboards, traffic signals or
      brands in clothing or objects). This is a challenging problem due to the complexity of the context where texts appear (uneven backgrounds, shading, occlusions, perspec-tive distortions, etc.). 
       Only a few approaches try to exploitthe relation between text and its surrounding environmentto better recognize text in the scene.  In this paper, we propose a visual context dataset for
        Text Spotting in the wild,where the publicly available dataset COCO-text (<a href="https://arxiv.org/pdf/1601.07140v2.pdf"> Veit al., 2016</a>)  has been  extended  with  information  about  the  scene  (such  asobjects  and  places  
       appearing  in  the  image)  to  enable  re-searchers to include semantic relations between texts andscene in their Text Spotting systems, and to offer a commonframework  for  such  approaches.   
       For  each  text  in  an  image, we extract three kinds of context information:  objectsin the scene, image location label and a textual image de-scription (caption).  We 
       use state-of-the-art out-of-the-box available tools to extract this additional information. Sincethis information has textual form, it can be used to
      leveragetext similarity or semantic relation methods into Text Spotting systems, either as a post-processing or in an end-to-end training strategy</a></tr>
</div>

</br>





<div class="container" text-align="left">
  <h2>Overview</h2>
    <table border="0" align="left">
      <tr><td width="1000" align="justify"> 
        <p align="justify"> We have proposed a dataset that extends COCO-text with visual context  information,  that  we  believe  useful  for  the text spotting problem. In contrast to the most recent method (<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Shitala_Prasad_Using_Object_Information_ECCV_2018_paper.pdf">Prasad al., 2018</a>)  
           that  relies  on  limited  classes  of  context  objects  anduses a complex architecture to extract visual information,our approach utilizes out-of-the-box state-of-the-art tools.Therefore,  
           the dataset annotation will be improved in thefuture as better systems become available. This dataset can be used to leverage semantic relation between image con-text and candidate texts into 
            text  spotting  systems,  either as post-processing or end-to-end training. We also use our dataset to train/tune an evaluate existing semantic similarity systems when applied to the task of re-ranking text hypothesis 
            produced by a text spotting baseline, showing that it canimprove the accuracy of the original baseline between 2 and3 points. Note that there’s a lot of room for improvement upto 7.4 points in a benchmark dataset.
       </br>

      

       
      
    
    
    
  
      <tr><td width="1000" align="left"> 
        <div class="paper" id="ap_agent">
          <h2>Dataset</h2>
          <p>   We proposed a variation of the COCO-text dataset and baseline BERT</p>
          <p align="center"> <img src="Figure-2-c-1.png" width="600" align="middle" /></p>
          <a shape="rect" href="javascript:togglebib('ap_agent')" class="togglebib">Training data<sub>COCO=text</sub></a>
          <pre xml:space="preserve">
            <strong>word</strong>, <strong>objects</strong>, <strong>places</strong>
            airfrance,airliner,airfield
            2010,microwave,utility room
            kefalotyri,radio,storage room
            stop,canoe,playground
            l-17,wing,heliport
            gree,street,skyscraper
          </pre>       
        </div>
      </td></tr>
      <tr><td width="1000" align="left"> 
        <div class="paper" id="ap_role_scenario1">
          <a shape="rect" href="javascript:togglebib('ap_role_scenario1')" class="togglebib">with Caption<sub>COCO-text</sub> </a>
          <pre >
            <strong>label</strong>, <strong>word</strong>, <strong>caption</strong>
            1,parking,a street sign with a sign on the side of it 
            1,chase,a man is playing tennis on a tennis court (tennis sponspr)
            0,sq,a small child is sitting on a couch with a laptop 
            1,paper,a desk with a laptop and a mouse on it 
            1,3,a parking meter with a parking meter on it  
            0,ie,a woman holding a pink umbrella in her hand 
          </pre>       
        </div>

      </td></tr>
      <tr><td width="1000" align="left"> 
        <div class="paper" id="ap_role_scenario1">
          <a shape="rect" href="javascript:togglebib('ap_role_scenario1')" class="togglebib">Test<sub>ICDAR-17</sub> </a>
          <pre >
            <strong>word</strong>, <strong>caption</strong>
            pizza, a person cutting a pizza with a fork and knife
            suit, a person in a suit and tie sitting with his hands between his legs.
            paddle, a person riding a colorful surfboard in the water.
          </pre>       
        </div>

      </td></tr>

    </td></tr>
    <tr><td width="1000" align="left"> 
      <div class="paper" id="ap_role_scenario1">
        <a shape="rect" href="javascript:togglebib('ap_role_scenario1')" class="togglebib">Test<sub>ICDAR-17</sub> </a>
        <pre >
          <strong>word</strong>, <strong>caption</strong>
          pizza, a person cutting a pizza with a fork and knife
          suit, a person in a suit and tie sitting with his hands between his legs.
          paddle, a person riding a colorful surfboard in the water.
        </pre>       
      </div>

    </td></tr>

      <tr><td width="1000" align="left"> 
        <div class="paper" id="ap_role_scenario1">
          <a shape="rect" href="javascript:togglebib('ap_role_scenario1')" class="togglebib">Object-and-text-co-occ<sub>COCO-text</sub></a>
          <pre >
          <strong>word</strong>, <strong>visual</strong>
           stop, street
           cable, remote
           airways, airliner
           4, volleyball
           food, broccoli
          </pre>       
        </div>
      </td></tr>      
    </table> 
</div>

</br>

<div style="text-align: center;" class="containersmall">
  <span align="center"><a href="bibtex.txt">[bibtex]</a></span>
  <p>Contact: <a href="mailto:asabir@cs.upc.edu">Ahmed Sabir</a></p>
</div>
 
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

</body>
</html>
